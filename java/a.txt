1.Hello everyone, this is Hudongling from the Fixed Income Data Platform team. It's my honor to introduce Flink SQL to all of you.
2.First question, what's the Flink SQL?  Flink SQL is a component of Apache Flink, it allows users to write real-time streaming Flink Job by SQL (Structured Query Language). User don't need to write complex Java or Scala code, only need to familiar with SQL, then can implement a Flink job.
3.Let's take look at an example and let you understand what Flink SQL is and how to use it. Let's  take a look at the following SQL, it is a simple CDC demo for quering MongoDB data. CDC means change data capture, which means any data changes in MongoDB can be monitored and captured by Flink SQL. Let's take a brief look at the CREATE statement, some column infos, with connector name, host, username and password and so on. OK, let me try to run it on our platform. As we can see, I only used a few lines of code and it can run a Flink job. And you need to pay attention to that this flink job has never been stopped even after all the data in MongoDB has been queried, Flink treats the MongoDB data source as unbounded streaming, and continuously monitors it's data change flow in real time. Actually this is a typical  scenario for Flink or Flink SQL, known as event-driven application. Flink can mark changing data as an event stream, and then drives Flink to perform calculations such as count and aggregate on those data, and finally sinks the result data to destination. OK, That's all for this slide.
4.Let me introduce the Flink SQL Platform briefly. The Flink SQL Platform is a platform that allows users to develop, test, run, and deploy their SQL. Some of concepts we need to focus on, like connectors and function, those are key concept on Flink SQL.
5.Connector, we know Flink is just a middle computation engine. If you want to connect with external data sources, of course, you need something like a connector, which connect external source for reading and writing. Kafka natural match with Flink, can be a source or sink as streaming mode. These are the connectors provided officially by Flink Community. If there isn't a connector you need, Flink SQL supports the customization of connectors. Flink SQL provides standardized abstract interfaces, you just need to implement them follow the steps one by one. like Mirror Lake and KDB, those are internal data source in Citi, we customize those connector for user.
6.The "workspace" is a concept within the platform used for resource isolation.